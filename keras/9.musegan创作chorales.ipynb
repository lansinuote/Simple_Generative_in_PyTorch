{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1,  1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1,  1, -1, -1, -1, -1, -1, -1]],\n",
       "\n",
       "       [[-1, -1, -1,  1, -1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1,  1, -1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1,  1, -1, -1, -1]],\n",
       "\n",
       "       [[-1, -1, -1, -1, -1, -1,  1, -1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1,  1, -1],\n",
       "        [-1, -1, -1, -1, -1, -1, -1, -1,  1]]], dtype=int32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#数字矩阵转one hot编码的函数\n",
    "def build_one_hot(data, max_value):\n",
    "    data = np.eye(max_value, dtype=np.int32)[data]\n",
    "    data[data == 0] = -1\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "build_one_hot(np.arange(9).reshape(3, 3), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data[0]= (192, 4) float16\n",
      "data[1]= (228, 4) float16\n",
      "data[2]= (208, 4) float16\n",
      "data[3]= (432, 4) float16\n",
      "data[4]= (260, 4) float16\n",
      "data[5]= (212, 4) float16\n",
      "data[6]= (292, 4) float16\n",
      "data[7]= (180, 4) float16\n",
      "data[8]= (132, 4) float16\n",
      "data[9]= (192, 4) float16\n",
      "data= (229,) object\n",
      "new_data= 229 (192, 4) (228, 4)\n",
      "data_cut= (229, 32, 4) int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((229, 2, 16, 84, 4), dtype('int32'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data():\n",
    "    #加载数据\n",
    "    data = np.load('../datas/chorales/Jsb16thSeparated.npz',\n",
    "                   encoding='bytes')['train']\n",
    "\n",
    "    #一共229首曲子,每个曲子长度不定,都是4个声部\n",
    "    for i in range(10):\n",
    "        print('data[%d]=' % i, data[i].shape, data[i].dtype)\n",
    "\n",
    "    print('data=', data.shape, data.dtype)\n",
    "\n",
    "    #筛除数据中的nan,这数据集做的简直是一坨屎\n",
    "    new_data = []\n",
    "    for song in data:\n",
    "        new_song = []\n",
    "        for time in song:\n",
    "            #time -> [4]\n",
    "\n",
    "            if np.isnan(time).any():\n",
    "                continue\n",
    "\n",
    "            new_song.append(time)\n",
    "\n",
    "        new_song = np.array(new_song, dtype=np.int32)\n",
    "        new_data.append(new_song)\n",
    "\n",
    "    print('new_data=', len(new_data), new_data[0].shape, new_data[1].shape)\n",
    "\n",
    "    #截取每首曲子的前32个拍子\n",
    "    data_cut = []\n",
    "    for song in new_data:\n",
    "        data_cut.append(song[:32])\n",
    "\n",
    "    #[229, 32, 4]\n",
    "    data_cut = np.array(data_cut)\n",
    "\n",
    "    print('data_cut=', data_cut.shape, data_cut.dtype)\n",
    "\n",
    "    #分成两条音轨,每条音轨16个拍子\n",
    "    #[229, 32, 4] -> [229, 2, 16, 4]\n",
    "    data_cut = data_cut.reshape([229, 2, 16, 4])\n",
    "\n",
    "    #转one hot编码\n",
    "    #[229, 2, 16, 4] -> [229, 2, 16, 4, 84]\n",
    "    data_cut = build_one_hot(data_cut, max_value=84)\n",
    "\n",
    "    #交换最后两个维度\n",
    "    #[229, 2, 16, 4, 84] -> [229, 2, 16, 84, 4]\n",
    "    data_cut = data_cut.transpose([0, 1, 2, 4, 3])\n",
    "\n",
    "    return data_cut\n",
    "\n",
    "\n",
    "data = get_data()\n",
    "\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4]), array([0.25, 0.25, 0.25, 0.25, 0.25], dtype=float32))\n",
      "(array([1., 1.]), array([1.  , 0.25], dtype=float32))\n",
      "(array([0, 1, 2, 3, 4, 5, 6]), array([0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25], dtype=float32))\n",
      "(array([1., 1.]), array([1.  , 0.75], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "def merge_note(note, duration=None):\n",
    "    if duration is None:\n",
    "        duration = np.full(note.shape, fill_value=0.25, dtype=np.float32)\n",
    "\n",
    "    #从前往后遍历\n",
    "    for i in range(len(note) - 1):\n",
    "        j = i + 1\n",
    "\n",
    "        #判断相连的两个note是否相同,并且duration相加不大于1.0\n",
    "        if note[i] == note[j] and duration[i] + duration[j] <= 1.0:\n",
    "\n",
    "            #duration合并\n",
    "            duration[i] += duration[j]\n",
    "\n",
    "            #删除重复的note\n",
    "            note = np.delete(note, j, axis=0)\n",
    "            duration = np.delete(duration, j, axis=0)\n",
    "\n",
    "            #递归调用\n",
    "            return merge_note(note, duration)\n",
    "\n",
    "    return note, duration\n",
    "\n",
    "\n",
    "print(merge_note(np.arange(5)))\n",
    "print(merge_note(np.ones(5)))\n",
    "\n",
    "print(merge_note(np.arange(7)))\n",
    "print(merge_note(np.ones(7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "\n",
    "\n",
    "def save_to_mid(data, filename):\n",
    "    #data -> [32, 4]\n",
    "    stream = music21.stream.Score()\n",
    "    stream.append(music21.tempo.MetronomeMark(number=66))\n",
    "\n",
    "    for i in range(4):\n",
    "        channel = music21.stream.Part()\n",
    "\n",
    "        notes, durations = merge_note(data[:, i])\n",
    "        notes, durations = notes.tolist(), durations.tolist()\n",
    "        for n, d in zip(notes, durations):\n",
    "            note = music21.note.Note(n)\n",
    "            note.duration = music21.duration.Duration(d)\n",
    "            channel.append(note)\n",
    "\n",
    "        stream.append(channel)\n",
    "\n",
    "    stream.write('midi', fp=filename)\n",
    "\n",
    "\n",
    "save_to_mid(data[0].argmax(axis=2).reshape(32, 4), 'sample.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv600'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv600');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQAEBABNVHJrAAAAXAD/AwAA4ABAAP9RAw3fIwCQSlqIAIBKAACQS1qIAIBLAACQTVqIAIBNAACQTVqIAIBNAACQS1qIAIBLAACQSlqIAIBKAACQSFqIAIBIAACQSFqIAIBIAIgA/y8ATVRyawAAAGcA/wMAAOAAQACQRlqIAIBGAACQRlqIAIBGAACQRVqIAIBFAACQRlqEAIBGAACQRVqEAIBFAACQQ1qEAIBDAACQRVqEAIBFAACQRlqIAIBGAACQRVqIAIBFAACQRVqIAIBFAIgA/y8ATVRyawAAAF4A/wMAAOAAQACQQVqIAIBBAACQOlqEAIA6AACQPFqEAIA8AACQPlqIAIA+AACQPlqIAIA+AACQP1qIAIA/AACQQVqIAIBBAACQQVqIAIBBAACQQVqIAIBBAIgA/y8ATVRyawAAAFUA/wMAAOAAQACQOlqIAIA6AACQN1qIAIA3AACQMlqIAIAyAACQN1qIAIA3AACQMFqIAIAwAACQLlqIAIAuAACQNVqIAIA1AACQNVqIAIA1AIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show(file):\n",
    "    f = music21.midi.MidiFile()\n",
    "    f.open(file)\n",
    "    f.read()\n",
    "    f.close()\n",
    "    music21.midi.translate.midiFileToStream(f).show('midi')\n",
    "\n",
    "\n",
    "show('sample.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f969b21acc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "weight_init = keras.initializers.RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "cls = keras.models.Sequential([\n",
    "    keras.layers.Conv3D(filters=128,\n",
    "                        kernel_size=(2, 1, 1),\n",
    "                        padding='valid',\n",
    "                        strides=(1, 1, 1),\n",
    "                        kernel_initializer=weight_init,\n",
    "                        input_shape=(2, 16, 84, 4)),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv3D(filters=128,\n",
    "                        kernel_size=(1, 1, 1),\n",
    "                        padding='valid',\n",
    "                        strides=(1, 1, 1),\n",
    "                        kernel_initializer=weight_init),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv3D(filters=128,\n",
    "                        kernel_size=(1, 1, 12),\n",
    "                        padding='same',\n",
    "                        strides=(1, 1, 12),\n",
    "                        kernel_initializer=weight_init),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv3D(filters=128,\n",
    "                        kernel_size=(1, 1, 7),\n",
    "                        padding='same',\n",
    "                        strides=(1, 1, 7),\n",
    "                        kernel_initializer=weight_init),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv3D(filters=128,\n",
    "                        kernel_size=(1, 2, 1),\n",
    "                        padding='same',\n",
    "                        strides=(1, 2, 1),\n",
    "                        kernel_initializer=weight_init),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv3D(filters=128,\n",
    "                        kernel_size=(1, 2, 1),\n",
    "                        padding='same',\n",
    "                        strides=(1, 2, 1),\n",
    "                        kernel_initializer=weight_init),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv3D(filters=256,\n",
    "                        kernel_size=(1, 4, 1),\n",
    "                        padding='same',\n",
    "                        strides=(1, 2, 1),\n",
    "                        kernel_initializer=weight_init),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Conv3D(filters=512,\n",
    "                        kernel_size=(1, 3, 1),\n",
    "                        padding='same',\n",
    "                        strides=(1, 2, 1),\n",
    "                        kernel_initializer=weight_init),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, kernel_initializer=weight_init),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(1, activation=None, kernel_initializer=weight_init),\n",
    "])\n",
    "\n",
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f95d6f2f8d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_gen():\n",
    "\n",
    "    def TemporalNetwork():\n",
    "        return keras.models.Sequential([\n",
    "            keras.layers.Reshape([1, 1, 32], input_shape=(32, )),\n",
    "            keras.layers.Conv2DTranspose(filters=1024,\n",
    "                                         kernel_size=(2, 1),\n",
    "                                         padding='valid',\n",
    "                                         strides=(1, 1),\n",
    "                                         kernel_initializer=weight_init),\n",
    "            keras.layers.BatchNormalization(momentum=0.9),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Conv2DTranspose(filters=32,\n",
    "                                         kernel_size=(1, 1),\n",
    "                                         padding='valid',\n",
    "                                         strides=(1, 1),\n",
    "                                         kernel_initializer=weight_init),\n",
    "            keras.layers.BatchNormalization(momentum=0.9),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Reshape([2, 32]),\n",
    "        ])\n",
    "\n",
    "    def BarGenerator():\n",
    "        return keras.models.Sequential([\n",
    "            keras.layers.Dense(1024, input_shape=(128, )),\n",
    "            keras.layers.BatchNormalization(momentum=0.9),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Reshape([2, 1, 512]),\n",
    "            keras.layers.Conv2DTranspose(filters=512,\n",
    "                                         kernel_size=(2, 1),\n",
    "                                         padding='same',\n",
    "                                         strides=(2, 1),\n",
    "                                         kernel_initializer=weight_init),\n",
    "            keras.layers.BatchNormalization(momentum=0.9),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Conv2DTranspose(filters=256,\n",
    "                                         kernel_size=(2, 1),\n",
    "                                         padding='same',\n",
    "                                         strides=(2, 1),\n",
    "                                         kernel_initializer=weight_init),\n",
    "            keras.layers.BatchNormalization(momentum=0.9),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Conv2DTranspose(filters=256,\n",
    "                                         kernel_size=(2, 1),\n",
    "                                         padding='same',\n",
    "                                         strides=(2, 1),\n",
    "                                         kernel_initializer=weight_init),\n",
    "            keras.layers.BatchNormalization(momentum=0.9),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Conv2DTranspose(filters=256,\n",
    "                                         kernel_size=(1, 7),\n",
    "                                         padding='same',\n",
    "                                         strides=(1, 7),\n",
    "                                         kernel_initializer=weight_init),\n",
    "            keras.layers.BatchNormalization(momentum=0.9),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Conv2DTranspose(filters=1,\n",
    "                                         kernel_size=(1, 12),\n",
    "                                         padding='same',\n",
    "                                         strides=(1, 12),\n",
    "                                         kernel_initializer=weight_init),\n",
    "            keras.layers.Activation('tanh'),\n",
    "            keras.layers.Reshape([1, 16, 84, 1]),\n",
    "        ])\n",
    "\n",
    "    input_chord = keras.layers.Input(shape=(32, ))\n",
    "    input_style = keras.layers.Input(shape=(32, ))\n",
    "    input_melody = keras.layers.Input(shape=(4, 32))\n",
    "    input_groove = keras.layers.Input(shape=(4, 32))\n",
    "\n",
    "    output_chord = TemporalNetwork()(input_chord)\n",
    "\n",
    "    output = []\n",
    "    for i in range(2):\n",
    "        output_c = []\n",
    "\n",
    "        for j in range(4):\n",
    "\n",
    "            output_melody = keras.models.Sequential([\n",
    "                keras.layers.Lambda(lambda x: x[:, j, :]),\n",
    "                TemporalNetwork(),\n",
    "                keras.layers.Lambda(lambda x: x[:, i, :])\n",
    "            ])(input_melody)\n",
    "\n",
    "            concat = keras.layers.Concatenate(axis=1)([\n",
    "                keras.layers.Lambda(lambda x: x[:, i, :])(output_chord),\n",
    "                input_style, output_melody,\n",
    "                keras.layers.Lambda(lambda x: x[:, j, :])(input_groove)\n",
    "            ])\n",
    "            output_c.append(BarGenerator()(concat))\n",
    "\n",
    "        output.append(keras.layers.Concatenate(axis=-1)(output_c))\n",
    "\n",
    "    output = keras.layers.Concatenate(axis=1)(output)\n",
    "\n",
    "    gen = keras.models.Model(\n",
    "        [input_chord, input_style, input_melody, input_groove], output)\n",
    "\n",
    "    return gen\n",
    "\n",
    "\n",
    "gen = get_gen()\n",
    "\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.training.Model at 0x7f95d62fd2b0>,\n",
       " <keras.engine.training.Model at 0x7f95d63dac18>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "def get_gan():\n",
    "\n",
    "    class RandomMerge(keras.layers.merge._Merge):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def _merge_function(self, inputs):\n",
    "            alpha = keras.backend.random_uniform((64, 1, 1, 1, 1))\n",
    "            return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "    def set_trainable(model, trainable):\n",
    "        model.trainable = trainable\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = trainable\n",
    "\n",
    "    set_trainable(gen, False)\n",
    "\n",
    "    input_cls = keras.layers.Input(shape=[2, 16, 84, 4])\n",
    "    input_chord = keras.layers.Input(shape=(32, ))\n",
    "    input_style = keras.layers.Input(shape=(32, ))\n",
    "    input_melody = keras.layers.Input(shape=(4, 32))\n",
    "    input_groove = keras.layers.Input(shape=(4, 32))\n",
    "\n",
    "    output_gen = gen([input_chord, input_style, input_melody, input_groove])\n",
    "\n",
    "    output_cls_fake = cls(output_gen)\n",
    "    output_cls_real = cls(input_cls)\n",
    "\n",
    "    input_merge = RandomMerge()([input_cls, output_gen])\n",
    "\n",
    "    output_cls_merge = cls(input_merge)\n",
    "\n",
    "    def get_grads_loss(y_true, y_pred, input_merge):\n",
    "        grads = keras.backend.gradients(y_pred, input_merge)[0]\n",
    "        grads = keras.backend.square(grads)\n",
    "        grads = keras.backend.sum(grads, axis=np.arange(1, len(grads.shape)))\n",
    "        grads = keras.backend.sqrt(grads)\n",
    "        grads = keras.backend.square(1 - grads)\n",
    "        return keras.backend.mean(grads)\n",
    "\n",
    "    grads_loss = partial(get_grads_loss, input_merge=input_merge)\n",
    "\n",
    "    def wasserstein(y_true, y_pred):\n",
    "        return -keras.backend.mean(y_true * y_pred)\n",
    "\n",
    "    cls_model = keras.models.Model(\n",
    "        inputs=[\n",
    "            input_cls, input_chord, input_style, input_melody, input_groove\n",
    "        ],\n",
    "        outputs=[output_cls_real, output_cls_fake, output_cls_merge])\n",
    "\n",
    "    cls_model.compile(loss=[wasserstein, wasserstein, grads_loss],\n",
    "                      optimizer=keras.optimizers.Adam(lr=0.001,\n",
    "                                                      beta_1=0.5,\n",
    "                                                      beta_2=0.9),\n",
    "                      loss_weights=[1, 1, 10])\n",
    "\n",
    "    set_trainable(cls, False)\n",
    "    set_trainable(gen, True)\n",
    "\n",
    "    gan = keras.models.Model(\n",
    "        [input_chord, input_style, input_melody, input_groove],\n",
    "        output_cls_fake)\n",
    "\n",
    "    gan.compile(optimizer=keras.optimizers.Adam(lr=0.001,\n",
    "                                                beta_1=0.5,\n",
    "                                                beta_2=0.9),\n",
    "                loss=wasserstein)\n",
    "\n",
    "    set_trainable(cls, True)\n",
    "\n",
    "    return gan, cls_model\n",
    "\n",
    "\n",
    "gan, cls_model = get_gan()\n",
    "\n",
    "gan, cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv2433'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv2433');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQAEBABNVHJrAAABNAD/AwAA4ABAAP9RAw3fIwCQMlqCAIAyAACQGlqCAIAaAACQPFqCAIA8AACQGlqCAIAaAACQQlqCAIBCAACQGlqCAIAaAACQSlqCAIBKAACQU1qCAIBTAACQMlqCAIAyAACQGlqCAIAaAACQSlqCAIBKAACQQlqCAIBCAACQMlqCAIAyAACQGlqCAIAaAACQMlqCAIAyAACQGlqCAIAaAACQUFqCAIBQAACQQlqCAIBCAACQD1qCAIAPAACQNFqCAIA0AACQHlqCAIAeAACQQlqCAIBCAACQUFqCAIBQAACQQlqCAIBCAACQUFqCAIBQAACQQlqCAIBCAACQUFqCAIBQAACQGlqCAIAaAACQTlqCAIBOAACQKlqCAIAqAACQNVqCAIA1AACQMlqCAIAyAIgA/y8ATVRyawAAAQkA/wMAAOAAQACQSVqCAIBJAACQPVqCAIA9AACQSVqEAIBJAACQPVqCAIA9AACQSVqCAIBJAACQPVqCAIA9AACQSVqEAIBJAACQPVqCAIA9AACQSVqCAIBJAACQQlqCAIBCAACQSVqCAIBJAACQPVqCAIA9AACQSVqCAIBJAACQJVqCAIAlAACQUVqCAIBRAACQOVqCAIA5AACQQ1qCAIBDAACQOVqCAIA5AACQGFqCAIAYAACQLVqGAIAtAACQRVqCAIBFAACQOVqCAIA5AACQKVqCAIApAACQOVqCAIA5AACQJlqCAIAmAACQLVqCAIAtAACQQ1qCAIBDAACQLVqCAIAtAIgA/y8ATVRyawAAAQAA/wMAAOAAQACQT1qCAIBPAACQDFqCAIAMAACQJ1qCAIAnAACQDFqCAIAMAACQJ1qEAIAnAACQL1qCAIAvAACQJ1qGAIAnAACQL1qCAIAvAACQHVqCAIAdAACQL1qCAIAvAACQDFqCAIAMAACQHVqEAIAdAACQKFqCAIAoAACQMVqCAIAxAACQOlqCAIA6AACQTlqCAIBOAACQKFqCAIAoAACQJVqCAIAlAACQMVqCAIAxAACQQFqCAIBAAACQKFqCAIAoAACQMVqCAIAxAACQSVqCAIBJAACQTlqCAIBOAACQMVqEAIAxAACQPVqCAIA9AACQQFqCAIBAAIgA/y8ATVRyawAAAO4A/wMAAOAAQACQPlqCAIA+AACQQlqCAIBCAACQTlqCAIBOAACQPlqGAIA+AACQL1qCAIAvAACQNlqCAIA2AACQPlqGAIA+AACQSFqCAIBIAACQPlqCAIA+AACQHFqCAIAcAACQPlqCAIA+AACQQlqCAIBCAACQDFqCAIAMAACQL1qCAIAvAACQH1qCAIAfAACQL1qEAIAvAACQQVqCAIBBAACQH1qCAIAfAACQL1qCAIAvAACQDFqCAIAMAACQH1qEAIAfAACQL1qEAIAvAACQE1qCAIATAACQQ1qCAIBDAACQL1qCAIAvAIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test():\n",
    "    chord = np.random.normal(0, 1, (1, 32))\n",
    "    style = np.random.normal(0, 1, (1, 32))\n",
    "    melody = np.random.normal(0, 1, (1, 4, 32))\n",
    "    groove = np.random.normal(0, 1, (1, 4, 32))\n",
    "\n",
    "    #[1, 2, 16, 84, 4]\n",
    "    pred = gen.predict([chord, style, melody, groove])\n",
    "\n",
    "    #[1, 2, 16, 84, 4] -> [1, 2, 16, 4]\n",
    "    pred = pred.argmax(axis=3)\n",
    "\n",
    "    #[1, 2, 16, 4] -> [32, 4]\n",
    "    pred = pred.reshape(32, 4)\n",
    "\n",
    "    save_to_mid(pred, 'pred.mid')\n",
    "\n",
    "    show('pred.mid')\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/gdl/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [8.912887, -0.85698175, -0.034562703, 0.98044306] 0.0040728305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gdl/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 [-27.792698, -267.06592, 231.58945, 0.76837736] -282.16797\n",
      "100 [-27.88805, -257.02512, 218.39185, 1.0745221] -225.14125\n",
      "150 [-18.23226, -43.738167, 19.566328, 0.59395784] -33.739716\n",
      "200 [-16.835743, -75.27756, 53.224827, 0.52169865] -45.045284\n",
      "250 [-15.013928, -43.07686, 21.97362, 0.60893106] -14.732184\n",
      "300 [-14.297857, -106.17346, 89.668396, 0.22072089] -97.43548\n",
      "350 [-14.1342125, -32.94745, 15.056252, 0.37569845] -12.34396\n",
      "400 [-12.606506, -67.773705, 48.30908, 0.68581194] -37.58142\n",
      "450 [-11.947504, -14.487357, 1.7038689, 0.08359844] -15.795556\n",
      "500 [-11.203049, -20.237303, 8.629093, 0.040516045] -6.5508084\n",
      "550 [-12.3838825, -23.784214, 9.745614, 0.16547178] -12.909263\n",
      "600 [-11.5849285, -35.62585, 22.524584, 0.15163384] -24.991646\n",
      "650 [-11.719839, -28.288511, 14.372057, 0.21966158] -16.3292\n",
      "700 [-10.081033, -24.602768, 12.748704, 0.17730309] -10.602691\n",
      "750 [-10.870434, -20.221205, 8.281688, 0.10690833] -7.7463045\n",
      "800 [-9.710244, -26.209225, 14.81569, 0.16832903] -12.453541\n",
      "850 [-9.430994, -15.119096, 4.843739, 0.08443623] -7.6122823\n",
      "900 [-9.68703, -20.41964, 9.861892, 0.08707178] -2.0840075\n",
      "950 [-10.114071, -17.73894, 6.2960553, 0.13288136] -6.283645\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "\n",
    "    def train_cls():\n",
    "        pos = np.ones((64, 1), dtype=np.int32)\n",
    "        neg = -np.ones((64, 1), dtype=np.int32)\n",
    "        dummy = np.zeros((64, 1), dtype=np.int32)\n",
    "\n",
    "        chord = np.random.normal(0, 1, (64, 32))\n",
    "        style = np.random.normal(0, 1, (64, 32))\n",
    "        melody = np.random.normal(0, 1, (64, 4, 32))\n",
    "        groove = np.random.normal(0, 1, (64, 4, 32))\n",
    "\n",
    "        data_sub = data[np.random.randint(0, data.shape[0], 64)]\n",
    "\n",
    "        loss_cls = cls_model.train_on_batch(\n",
    "            [data_sub, chord, style, melody, groove], [pos, neg, dummy])\n",
    "\n",
    "        return loss_cls\n",
    "\n",
    "    def train_gen():\n",
    "        pos = np.ones((64, 1), dtype=np.int32)\n",
    "\n",
    "        chord = np.random.normal(0, 1, (64, 32))\n",
    "        style = np.random.normal(0, 1, (64, 32))\n",
    "        melody = np.random.normal(0, 1, (64, 4, 32))\n",
    "        groove = np.random.normal(0, 1, (64, 4, 32))\n",
    "\n",
    "        loss_gen = gan.train_on_batch([chord, style, melody, groove], pos)\n",
    "\n",
    "        return loss_gen\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        for _ in range(5):\n",
    "            loss_cls = train_cls()\n",
    "\n",
    "        loss_gen = train_gen()\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(epoch, loss_cls, loss_gen)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv5292'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv5292');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQAEBABNVHJrAAAAvwD/AwAA4ABAAP9RAw3fIwCQSlqEAIBKAACQQVqCAIBBAACQSlqCAIBKAACQQVqIAIBBAACQSlqEAIBKAACQQVqCAIBBAACQSlqCAIBKAACQQVqIAIBBAACQR1qIAIBHAACQN1qCAIA3AACQQFqCAIBAAACQR1qEAIBHAACQN1qCAIA3AACQR1qCAIBHAACQN1qEAIA3AACQL1qCAIAvAACQR1qCAIBHAACQL1qCAIAvAACQR1qCAIBHAIgA/y8ATVRyawAAAK8A/wMAAOAAQACQRlqCAIBGAACQQVqCAIBBAACQQ1qIAIBDAACQQ1qEAIBDAACQRlqIAIBGAACQQVqEAIBBAACQRlqCAIBGAACQQ1qCAIBDAACQQVqCAIBBAACQO1qCAIA7AACQQVqCAIBBAACQO1qCAIA7AACQQVqCAIBBAACQO1qGAIA7AACQQVqGAIBBAACQO1qCAIA7AACQQVqGAIBBAACQO1qCAIA7AIgA/y8ATVRyawAAAHAA/wMAAOAAQACQNVqIAIA1AACQP1qGAIA/AACQNVqIAIA1AACQNVqIAIA1AACQNVqCAIA1AACQN1qIAIA3AACQOlqIAIA6AACQN1qCAIA3AACQPVqGAIA9AACQOlqEAIA6AACQN1qEAIA3AIgA/y8ATVRyawAAAFUA/wMAAOAAQACQL1qIAIAvAACQNVqIAIA1AACQL1qIAIAvAACQNVqIAIA1AACQKVqIAIApAACQLlqIAIAuAACQLlqIAIAuAACQLlqIAIAuAIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
